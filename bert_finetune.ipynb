{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb3ae4371d214130b82ecd897e5c918d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e713a4ba99d436d9efb0011bb74bf8c",
              "IPY_MODEL_5b69a6e548724954855ef5cefe8cbd45",
              "IPY_MODEL_a8f02048df2b41c396ad60400fde9134"
            ],
            "layout": "IPY_MODEL_cc26941f2a4f455d9e3fff49a0d690f7"
          }
        },
        "1e713a4ba99d436d9efb0011bb74bf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593fbc1b8eba49b7857d0d3a73329eb5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0d8b4aeb193348a5891137a7c6e7df53",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "5b69a6e548724954855ef5cefe8cbd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63aa202f7954802a6bdb3b87a177b01",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d8858c31d964ca085a73b1c06b2801c",
            "value": 498818054
          }
        },
        "a8f02048df2b41c396ad60400fde9134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14174dd4d494c9c9d7f83e1bc1e54f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_082dae9e17754718a47db21e5482eebb",
            "value": "‚Äá499M/499M‚Äá[00:01&lt;00:00,‚Äá392MB/s]"
          }
        },
        "cc26941f2a4f455d9e3fff49a0d690f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593fbc1b8eba49b7857d0d3a73329eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8b4aeb193348a5891137a7c6e7df53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63aa202f7954802a6bdb3b87a177b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8858c31d964ca085a73b1c06b2801c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d14174dd4d494c9c9d7f83e1bc1e54f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082dae9e17754718a47db21e5482eebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq datasets"
      ],
      "metadata": {
        "id": "uEkQQgj2QVPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7cac96-348c-4a9a-8931-8efee0872ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/527.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h003HVeJtt7"
      },
      "outputs": [],
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conll(file_path):\n",
        "    sentences = []\n",
        "    sentence_labels = []\n",
        "    unique_labels = set()  # To collect unique labels\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        current_sentence_tokens = []\n",
        "        current_sentence_labels = []\n",
        "\n",
        "        for line in file:\n",
        "            line = line.strip()  # Remove leading/trailing whitespace, including '\\n'\n",
        "\n",
        "            # If it's an empty line, sentence boundary detected\n",
        "            if not line:\n",
        "                if current_sentence_tokens:  # Check if there's a sentence to append\n",
        "                    sentences.append(' '.join(current_sentence_tokens))\n",
        "                    sentence_labels.append(' '.join(current_sentence_labels))\n",
        "                current_sentence_tokens = []  # Reset for the next sentence\n",
        "                current_sentence_labels = []  # Reset for the next sentence\n",
        "            else:\n",
        "                line_parts = line.split()  # Split line into token and label\n",
        "                current_sentence_tokens.append(line_parts[0])\n",
        "\n",
        "                if len(line_parts) >= 2:\n",
        "                    current_sentence_labels.append(line_parts[1])\n",
        "                    unique_labels.add(line_parts[1])  # Add label to the set of unique labels\n",
        "                else:\n",
        "                    current_sentence_labels.append('O')  # Default to 'O' if no label provided\n",
        "\n",
        "    # Append the last sentence if the file doesn't end with an empty line\n",
        "    if current_sentence_tokens:\n",
        "        sentences.append(' '.join(current_sentence_tokens))\n",
        "        sentence_labels.append(' '.join(current_sentence_labels))\n",
        "\n",
        "    print(f\"Unique labels found: {unique_labels}\")\n",
        "    return sentences, sentence_labels\n",
        "\n",
        "# Load the datasets\n",
        "test_sentences, test_labels = read_conll('./test_word.conll')\n",
        "dev_sentences, dev_labels = read_conll('./dev_word.conll')\n",
        "train_sentences, train_labels = read_conll('./train_word.conll')\n",
        "\n",
        "# Now, test_sentences, test_labels, dev_sentences, dev_labels, train_sentences, and train_labels are arrays of strings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJYBvre1KXnM",
        "outputId": "d88a38dd-ae8c-4810-cd65-55f785ab9ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels found: {'I-LOCATION', 'I-PATIENT_ID', 'B-LOCATION', 'B-ORGANIZATION', 'B-DATE', 'I-TRANSPORTATION', 'O', 'B-GENDER', 'I-JOB', 'I-AGE', 'B-AGE', 'B-NAME', 'I-DATE', 'I-SYMPTOM_AND_DISEASE', 'B-TRANSPORTATION', 'B-SYMPTOM_AND_DISEASE', 'B-JOB', 'B-PATIENT_ID', 'I-NAME', 'I-ORGANIZATION'}\n",
            "Unique labels found: {'I-LOCATION', 'I-PATIENT_ID', 'B-LOCATION', 'B-ORGANIZATION', 'B-DATE', 'I-TRANSPORTATION', 'O', 'B-GENDER', 'I-JOB', 'B-AGE', 'B-NAME', 'I-SYMPTOM_AND_DISEASE', 'I-DATE', 'B-TRANSPORTATION', 'B-SYMPTOM_AND_DISEASE', 'B-JOB', 'B-PATIENT_ID', 'I-NAME', 'I-ORGANIZATION'}\n",
            "Unique labels found: {'I-LOCATION', 'I-PATIENT_ID', 'B-LOCATION', 'B-ORGANIZATION', 'B-DATE', 'I-TRANSPORTATION', 'O', 'B-GENDER', 'I-JOB', 'I-AGE', 'B-AGE', 'B-NAME', 'I-SYMPTOM_AND_DISEASE', 'I-DATE', 'B-TRANSPORTATION', 'B-SYMPTOM_AND_DISEASE', 'B-JOB', 'B-PATIENT_ID', 'I-NAME', 'I-ORGANIZATION'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GOu89ewfKbcN",
        "outputId": "9c673944-feb9-477e-f9c5-1475291672c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'B√°c_sƒ© Tr·∫ßn_Thanh_Linh , t·ª´ B·ªánh_vi·ªán Ch·ª£_R·∫´y chi_vi·ªán ph·ª•_tr√°ch ƒë∆°n_nguy√™n h·ªìi_s·ª©c t√≠ch_c·ª±c , cho bi·∫øt \" b·ªánh_nh√¢n 416 \" v·∫´n ƒëang duy_tr√¨ ECMO , th·ªü m√°y , hi·ªán x∆° ph·ªïi r·∫•t nhi·ªÅu .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Uf52SCP5Kgzn",
        "outputId": "fc992dc9-26d5-4368-f00b-599a91fda6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O O O O B-ORGANIZATION I-ORGANIZATION O O O O O O O O O O B-PATIENT_ID O O O O O O O O O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE I-SYMPTOM_AND_DISEASE O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Step 1: Prepare the datasets from sentences and labels\n",
        "def prepare_dataset(sentences, labels):\n",
        "    return {'tokens': sentences, 'labels': labels}\n",
        "\n",
        "train_dataset = prepare_dataset(train_sentences, train_labels)\n",
        "dev_dataset = prepare_dataset(dev_sentences, dev_labels)\n",
        "test_dataset = prepare_dataset(test_sentences, test_labels)\n",
        "\n",
        "# Step 2: Convert strings of tokens and labels into arrays\n",
        "def process_string_to_array(dataset):\n",
        "    return {\n",
        "        'tokens': [sentence.split() for sentence in dataset['tokens']],\n",
        "        'labels': [label_seq.split() for label_seq in dataset['labels']]\n",
        "    }\n",
        "\n",
        "# Step 3: Process the dataset for token and label lists\n",
        "train_dataset = process_string_to_array(train_dataset)\n",
        "dev_dataset = process_string_to_array(dev_dataset)\n",
        "test_dataset = process_string_to_array(test_dataset)\n",
        "\n",
        "# Step 4: Convert processed datasets into Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n",
        "dev_dataset = Dataset.from_dict(dev_dataset)\n",
        "test_dataset = Dataset.from_dict(test_dataset)\n",
        "\n",
        "# Print the size of each dataset and a sample for verification\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Dev dataset size: {len(dev_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "print(\"Train dataset sample:\", train_dataset[0])\n",
        "print(\"Dev dataset sample:\", dev_dataset[0])\n",
        "print(\"Test dataset sample:\", test_dataset[0])\n",
        "\n",
        "# Step 5: Define an Example class\n",
        "class Example:\n",
        "    def __init__(self, words, slot_labels, guid=None):\n",
        "        self.words = words\n",
        "        self.slot_labels = slot_labels\n",
        "        self.guid = guid\n",
        "\n",
        "# Step 6: Convert the dataset to Example objects\n",
        "def convert_to_examples(dataset):\n",
        "    return [\n",
        "        Example(words=tokens, slot_labels=labels, guid=i)\n",
        "        for i, (tokens, labels) in enumerate(zip(dataset['tokens'], dataset['labels']))\n",
        "    ]\n",
        "\n",
        "# Convert datasets into Example objects\n",
        "train_examples = convert_to_examples(train_dataset)\n",
        "dev_examples = convert_to_examples(dev_dataset)\n",
        "test_examples = convert_to_examples(test_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpwbDRI4bXY0",
        "outputId": "9aa96aac-793b-43f0-fd49-ec518d7becdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 5027\n",
            "Dev dataset size: 2000\n",
            "Test dataset size: 3000\n",
            "Train dataset sample: {'tokens': ['ƒê·ªìng_th·ªùi', ',', 'b·ªánh_vi·ªán', 'ti·∫øp_t·ª•c', 'th·ª±c_hi·ªán', 'c√°c', 'bi·ªán_ph√°p', 'ph√≤ng_ch·ªëng', 'd·ªãch_b·ªánh', 'COVID', '-', '19', 'theo', 'h∆∞·ªõng_d·∫´n', 'c·ªßa', 'B·ªô', 'Y_t·∫ø', '.'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'O']}\n",
            "Dev dataset sample: {'tokens': ['B√°c_sƒ©', 'Nguy·ªÖn_Trung_Nguy√™n', ',', 'Gi√°m_ƒë·ªëc', 'Trung_t√¢m', 'Ch·ªëng', 'ƒë·ªôc', ',', 'B·ªánh_vi·ªán', 'B·∫°ch_Mai', ',', 'cho', 'bi·∫øt', 'b·ªánh_nh√¢n', 'ƒë∆∞·ª£c', 'chuy·ªÉn', 'ƒë·∫øn', 'b·ªánh_vi·ªán', 'ng√†y', '7/3', ',', 'ch·∫©n_ƒëo√°n', 'ng·ªô_ƒë·ªôc', 'thu·ªëc', 'ƒëi·ªÅu_tr·ªã', 's·ªët_r√©t', 'chloroquine', '.'], 'labels': ['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'B-SYMPTOM_AND_DISEASE', 'I-SYMPTOM_AND_DISEASE', 'O', 'O', 'O', 'O']}\n",
            "Test dataset sample: {'tokens': ['T·ª´', '24', '-', '7', 'ƒë·∫øn', '31', '-', '7', ',', 'b·ªánh_nh√¢n', 'ƒë∆∞·ª£c', 'm·∫π', 'l√†', 'b√†', 'H.T.P', '(', '47', 'tu·ªïi', ')', 'ƒë√≥n', 'v·ªÅ', 'nh√†', '·ªü', 'ph∆∞·ªùng', 'Ph∆∞·ªõc_Ho√†', '(', 'b·∫±ng', 'xe_m√°y', ')', ',', 'kh√¥ng', 'ƒëi', 'ƒë√¢u', 'ch·ªâ', 'ra', 'T·∫°p_ho√°', 'Ph∆∞·ª£ng', ',', 'ch·ª£', 'V∆∞·ªùn_L√†i', ',', 'ph∆∞·ªùng', 'An_S∆°n', 'c√πng', 'm·∫π', 'b√°n', 't·∫°p_ho√°', '·ªü', 'ƒë√¢y', '.'], 'labels': ['O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME', 'O', 'B-AGE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'B-JOB', 'I-JOB', 'O', 'O', 'O']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import os"
      ],
      "metadata": {
        "id": "KY8Z5RMYS0pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    max_seq_len,\n",
        "    tokenizer,\n",
        "    pad_label_id=-100,\n",
        "    cls_token_segment_id=0,\n",
        "    pad_token_segment_id=0,\n",
        "    sequence_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    # Get special tokens from the tokenizer\n",
        "    cls_token = tokenizer.cls_token\n",
        "    sep_token = tokenizer.sep_token\n",
        "    unk_token = tokenizer.unk_token\n",
        "    pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    # List to hold the converted features\n",
        "    features = []\n",
        "\n",
        "    for example_index, example in enumerate(examples):\n",
        "        # Log progress every 5000 examples\n",
        "        if example_index % 400 == 0:\n",
        "            logger.info(f\"Processing example {example_index} of {len(examples)}\")\n",
        "\n",
        "        # Tokenize each word and align its corresponding label\n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "\n",
        "        for word, label in zip(example.words, example.slot_labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "\n",
        "            # If the word cannot be tokenized, use [UNK] token\n",
        "            if not word_tokens:\n",
        "                word_tokens = [unk_token]\n",
        "\n",
        "            tokens.extend(word_tokens)\n",
        "\n",
        "            # Map string label to integer ID, apply pad_label_id for subword tokens\n",
        "            label_id = label_map[label]\n",
        "            label_ids.extend([label_id] + [pad_label_id] * (len(word_tokens) - 1))\n",
        "\n",
        "        # Handle sequence truncation for [CLS] and [SEP] tokens\n",
        "        special_tokens_count = 2\n",
        "        if len(tokens) > max_seq_len - special_tokens_count:\n",
        "            tokens = tokens[:max_seq_len - special_tokens_count]\n",
        "            label_ids = label_ids[:max_seq_len - special_tokens_count]\n",
        "\n",
        "        # Add [SEP] token at the end of the sentence\n",
        "        tokens.append(sep_token)\n",
        "        label_ids.append(pad_label_id)\n",
        "        token_type_ids = [sequence_segment_id] * len(tokens)\n",
        "\n",
        "        # Add [CLS] token at the start of the sentence\n",
        "        tokens = [cls_token] + tokens\n",
        "        label_ids = [pad_label_id] + label_ids\n",
        "        token_type_ids = [cls_token_segment_id] + token_type_ids\n",
        "\n",
        "        # Convert tokens to input IDs\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Create attention masks (1 for real tokens, 0 for padding tokens)\n",
        "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "\n",
        "        # Pad sequences to the maximum sequence length\n",
        "        padding_length = max_seq_len - len(input_ids)\n",
        "        input_ids += [pad_token_id] * padding_length\n",
        "        attention_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
        "        token_type_ids += [pad_token_segment_id] * padding_length\n",
        "        label_ids += [pad_label_id] * padding_length\n",
        "\n",
        "        # Create InputFeatures object and append it to the list of features\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids,\n",
        "                slot_labels_ids=label_ids,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "93kM19XPSvix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the label list (ensure that it includes all labels from your dataset)\n",
        "label_list = ['B-ORGANIZATION', 'B-TRANSPORTATION', 'B-JOB', 'I-PATIENT_ID', 'B-NAME', 'I-DATE', 'O', 'B-PATIENT_ID', 'I-AGE', 'I-JOB', 'B-DATE', 'I-TRANSPORTATION', 'B-SYMPTOM_AND_DISEASE', 'I-SYMPTOM_AND_DISEASE', 'B-GENDER', 'I-NAME', 'B-LOCATION', 'I-LOCATION', 'I-ORGANIZATION', 'B-AGE']\n",
        "\n",
        "# Create a mapping from label strings to integers\n",
        "label_map = {label: i for i, label in enumerate(label_list)}\n"
      ],
      "metadata": {
        "id": "gPwTywxOTC2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "j1gDFp4WTtg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, attention_mask, token_type_ids, slot_labels_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.slot_labels_ids = slot_labels_ids\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\""
      ],
      "metadata": {
        "id": "_1BFV0caTUT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.cls_token, tokenizer.sep_token, tokenizer.unk_token, tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3jxMCeOLr8z",
        "outputId": "dd3aa9fe-6157-4190-a672-9d118f97cc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<s>', '</s>', '<unk>', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', add_prefix_space=True)\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_seq_len = 128  # You can adjust this based on your model/input\n",
        "\n",
        "# Convert examples to features\n",
        "train_features = convert_examples_to_features(train_examples, max_seq_len, tokenizer)\n",
        "dev_features = convert_examples_to_features(dev_examples, max_seq_len, tokenizer)\n",
        "test_features = convert_examples_to_features(test_examples, max_seq_len, tokenizer)\n"
      ],
      "metadata": {
        "id": "8L7QmU9OSkQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Define a Dataset class to wrap the tokenized features for training\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        return {\n",
        "            'input_ids': torch.tensor(feature.input_ids, dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(feature.attention_mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(feature.token_type_ids, dtype=torch.long),\n",
        "            'labels': torch.tensor(feature.slot_labels_ids, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Convert tokenized features into PyTorch datasets\n",
        "train_dataset = NERDataset(train_features)\n",
        "dev_dataset = NERDataset(dev_features)\n",
        "test_dataset = NERDataset(test_features)\n"
      ],
      "metadata": {
        "id": "wIpgQ1koT5um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbw028u8Na6Z",
        "outputId": "13d27053-fbb6-4426-c14a-0daa70b3ed7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    0,  4236, 16948,  1376,  2023,  9085,  2590,  1215,   212,  1376,\n",
              "          2023,    46,   118,  2156,   741,  1376,  2023,  6382,   282,   298,\n",
              "          1215,  6873,  1376,  2023,  6382,   282, 12369,  1376,  3070,  9470,\n",
              "           642,  1215,    90,  1376,  2023,  8210,   438,  3553,  1376,  2023,\n",
              "         15389,   438,  1215,  3592,  1376,  2023,  6382,   282,   740,  1526,\n",
              "           438,  4003,  1376,  2023,  6382,   282,  1215,  3792,  1526,   642,\n",
              "          7843,  3849, 14292,  2590,  1215,   611,  1376,  2023,  3602,  2590,\n",
              "           385,  1376,  2023, 13859,   611,  1215,   428,  1376,  2023,  6382,\n",
              "           282,   298,  6247, 43814,   111,   753,     5,   139,  1368,  8188,\n",
              "          7487,  1376,  2023,  3726,  2590,  1215,   417,  1376,  3070,  4958,\n",
              "           282,   740,  1376,  2023,  6248,   102,   163,  1376,  2023,    27,\n",
              "           854,  1215,    90,  1376,  3070,  9470,   479,     2,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor([-100,    6, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100,    6,    6, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100,    6, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100,    6, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "            6, -100, -100,    6, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "            6, -100, -100, -100, -100, -100, -100, -100, -100, -100,    6, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    6, -100,\n",
              "            6,    6,    6, -100,    6, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100,    6, -100, -100, -100, -100,    0, -100,\n",
              "         -100, -100,   18, -100, -100, -100, -100, -100,    6, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForTokenClassification\n",
        "\n",
        "# Define the number of unique labels (ensure this matches your dataset's label set)\n",
        "num_labels = len(label_list)  # e.g., the number of unique labels such as O, B-ORG, etc.\n",
        "\n",
        "# Load the RoBERTa model for token classification\n",
        "model = RobertaForTokenClassification.from_pretrained('roberta-base', num_labels=num_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "eb3ae4371d214130b82ecd897e5c918d",
            "1e713a4ba99d436d9efb0011bb74bf8c",
            "5b69a6e548724954855ef5cefe8cbd45",
            "a8f02048df2b41c396ad60400fde9134",
            "cc26941f2a4f455d9e3fff49a0d690f7",
            "593fbc1b8eba49b7857d0d3a73329eb5",
            "0d8b4aeb193348a5891137a7c6e7df53",
            "e63aa202f7954802a6bdb3b87a177b01",
            "6d8858c31d964ca085a73b1c06b2801c",
            "d14174dd4d494c9c9d7f83e1bc1e54f9",
            "082dae9e17754718a47db21e5482eebb"
          ]
        },
        "id": "4giDkLYOUB57",
        "outputId": "69636a80-5b44-48ee-8021-06e688de857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb3ae4371d214130b82ecd897e5c918d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory to save model checkpoints and results\n",
        "    evaluation_strategy=\"epoch\",      # evaluation is done at the end of every epoch\n",
        "    per_device_train_batch_size=16,   # batch size per device during training\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    num_train_epochs=3,               # number of epochs to train the model\n",
        "    weight_decay=0.01,                # strength of weight decay\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,                 # log every 10 steps\n",
        "    save_steps=500,                   # save model checkpoint every 500 steps\n",
        "    save_total_limit=2,               # limit the number of total checkpoints to save\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD9Coch-UECW",
        "outputId": "74724e71-536e-4131-8a8a-8fba5ba76a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CmjNJmGW8Qe",
        "outputId": "2c8d0610-8765-409d-ca4d-d1250cbc617d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=52f50667b01fb16a78069384b176ffeace63aff03e9607da331570d145c07dec\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C3PSdHdY0zE",
        "outputId": "472e7d93-8014-44c1-f831-9eff2af8e42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORGANIZATION',\n",
              " 'B-TRANSPORTATION',\n",
              " 'B-JOB',\n",
              " 'I-PATIENT_ID',\n",
              " 'B-NAME',\n",
              " 'I-DATE',\n",
              " 'O',\n",
              " 'B-PATIENT_ID',\n",
              " 'I-AGE',\n",
              " 'I-JOB',\n",
              " 'B-DATE',\n",
              " 'I-TRANSPORTATION',\n",
              " 'B-SYMPTOM_AND_DISEASE',\n",
              " 'I-SYMPTOM_AND_DISEASE',\n",
              " 'B-GENDER',\n",
              " 'I-NAME',\n",
              " 'B-LOCATION',\n",
              " 'I-LOCATION',\n",
              " 'I-ORGANIZATION',\n",
              " 'B-AGE']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EvalPrediction\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions = p.predictions.argmax(axis=2)  # Get predicted label indices\n",
        "    labels = p.label_ids  # True label IDs\n",
        "\n",
        "    # Debugging: Print shapes of predictions and labels\n",
        "    print(f\"Shape of predictions: {predictions.shape}\")\n",
        "    print(f\"Shape of labels: {labels.shape}\")\n",
        "\n",
        "    # Debugging: Log first few predictions and labels for inspection\n",
        "    print(f\"First few predictions: {predictions[:2]}\")\n",
        "    print(f\"First few labels: {labels[:2]}\")\n",
        "\n",
        "    pred_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Iterate through predictions and labels\n",
        "    for i, (pred_seq, true_seq) in enumerate(zip(predictions, labels)):\n",
        "        pred_label_seq = []\n",
        "        true_label_seq = []\n",
        "\n",
        "        # Iterate through each token in the sequence\n",
        "        for pred_idx, true_idx in zip(pred_seq, true_seq):\n",
        "            if true_idx == -100:\n",
        "                # Debugging: Log any padding tokens encountered\n",
        "                # print(f\"Padding token encountered at position {i}\")\n",
        "                continue\n",
        "\n",
        "            # Check if the indices are within the valid range\n",
        "            if pred_idx < len(label_list) and true_idx < len(label_list):\n",
        "                pred_label_seq.append(label_list[pred_idx])\n",
        "                true_label_seq.append(label_list[true_idx])\n",
        "            else:\n",
        "                # Debugging: Log when out-of-bound indices are encountered\n",
        "                print(f\"Index out of range: pred_idx={pred_idx}, true_idx={true_idx} at position {i}\")\n",
        "\n",
        "        pred_labels.append(pred_label_seq)\n",
        "        true_labels.append(true_label_seq)\n",
        "\n",
        "    # Debugging: Log final processed predictions and labels\n",
        "    print(f\"Processed pred_labels: {pred_labels[:2]}\")\n",
        "    print(f\"Processed true_labels: {true_labels[:2]}\")\n",
        "\n",
        "    # Compute token-level F1, Precision, and Recall\n",
        "    precision = precision_score(true_labels, pred_labels)\n",
        "    # Trong 10 l·∫ßn d·ª± ƒëo√°n nh√£n PER: th√¨ ch√∫ng ta ƒëo√°n ƒë√∫ng 6 l·∫ßn -> 6/10 = 60%\n",
        "\n",
        "    recall = recall_score(true_labels, pred_labels)\n",
        "    # Trong 8 nh√£n PER th·∫≠t: th√¨ ch√∫ng ta ƒëo√°n ƒë√∫ng 6 l·∫ßn -> 6/8 = 75%\n",
        "\n",
        "    f1 = f1_score(true_labels, pred_labels)\n",
        "\n",
        "    # Debugging: Print classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true_labels, pred_labels))\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ],
      "metadata": {
        "id": "L3gD8zJQW4j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "from transformers import EvalPrediction\n"
      ],
      "metadata": {
        "id": "ot0X4_cLb1vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer with the modified compute_metrics function\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics  # Updated function\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "jxgd98KnUJzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7317bd74-6896-4f61-a020-ececcbe2e60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 06:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>0.252638</td>\n",
              "      <td>0.789760</td>\n",
              "      <td>0.840457</td>\n",
              "      <td>0.814320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.060800</td>\n",
              "      <td>0.131611</td>\n",
              "      <td>0.885309</td>\n",
              "      <td>0.899170</td>\n",
              "      <td>0.892186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.056100</td>\n",
              "      <td>0.127506</td>\n",
              "      <td>0.885836</td>\n",
              "      <td>0.913574</td>\n",
              "      <td>0.899491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of predictions: (2000, 128)\n",
            "Shape of labels: (2000, 128)\n",
            "First few predictions: [[ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 16  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6 16 17  6  6 17 17 17 17 17 17 17  6  6  6  6\n",
            "   6  6  6 16 16 17 17 17 17  6 16 17 17 17 17 17 17 17 17 17  6 17 17  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6 10  5  5  6]\n",
            " [ 6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  6  6 14  6  6 19  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 16\n",
            "  16 17 17 17 17 17 17 17 17  6 16 17 17  6 17 17 17  6 16 16  6 17 17 17\n",
            "  17 17  6  6  6  6  6  6  6  6 16 16 17 17 17 17 17 17 17 17  6 16 17 17\n",
            "  17  6 17  6 17  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  7  7  6  6  6  6  6]]\n",
            "First few labels: [[-100    6 -100 -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100    6    6 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100   18 -100 -100\n",
            "  -100 -100   18 -100 -100 -100 -100 -100   18   18 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100   18 -100 -100 -100 -100 -100 -100\n",
            "  -100    6    6    6 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100 -100 -100    6\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100    6 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6 -100 -100   10 -100\n",
            "  -100 -100]\n",
            " [-100    6    6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100    7\n",
            "  -100    6    6   14 -100    6   19    6 -100 -100 -100 -100    6    6\n",
            "  -100    2 -100 -100 -100 -100 -100 -100 -100    9 -100    9 -100 -100\n",
            "    16 -100 -100 -100 -100   17   17 -100 -100 -100   17 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6   16 -100 -100 -100\n",
            "  -100 -100 -100 -100    6    6 -100    6 -100 -100 -100 -100   16 -100\n",
            "  -100 -100 -100   17 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100    6    6 -100 -100    6 -100 -100 -100    6    6 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    7 -100    6    6    6\n",
            "  -100 -100]]\n",
            "Processed pred_labels: [['O', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOCATION', 'B-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Processed true_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'I-JOB', 'I-JOB', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.88      0.97      0.92       308\n",
            "               DATE       0.94      0.99      0.96       993\n",
            "             GENDER       0.85      0.94      0.90       245\n",
            "                JOB       0.00      0.00      0.00       112\n",
            "           LOCATION       0.70      0.88      0.78      2295\n",
            "               NAME       0.96      0.73      0.83       169\n",
            "       ORGANIZATION       0.54      0.33      0.41       500\n",
            "         PATIENT_ID       0.93      0.98      0.96      1067\n",
            "SYMPTOM_AND_DISEASE       0.71      0.70      0.70       619\n",
            "     TRANSPORTATION       0.86      0.85      0.85        79\n",
            "\n",
            "          micro avg       0.79      0.84      0.81      6387\n",
            "          macro avg       0.74      0.74      0.73      6387\n",
            "       weighted avg       0.78      0.84      0.80      6387\n",
            "\n",
            "Shape of predictions: (2000, 128)\n",
            "Shape of labels: (2000, 128)\n",
            "First few predictions: [[ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  0 18  6 18 18 18 18 18 18 18 18 18 18 18 18\n",
            "  18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6 10  5  5  6]\n",
            " [ 6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  6  6 14  6  6 19  6  6  6\n",
            "   6  6  6  6  6 14  6  6  6  6  6  6  6  6  6  6  6 17  6  6  6  6  6 16\n",
            "  17 17 17 17 17 17 17 17 17 17 16 17 17 17 17 17 17  6 16 17 17 17 17 17\n",
            "  17 17  6  6  6  6  6  6  6  6 16 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
            "  17 17 17  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   7  7  7  6  6  6  6  6]]\n",
            "First few labels: [[-100    6 -100 -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100    6    6 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100   18 -100 -100\n",
            "  -100 -100   18 -100 -100 -100 -100 -100   18   18 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100   18 -100 -100 -100 -100 -100 -100\n",
            "  -100    6    6    6 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100 -100 -100    6\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100    6 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6 -100 -100   10 -100\n",
            "  -100 -100]\n",
            " [-100    6    6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100    7\n",
            "  -100    6    6   14 -100    6   19    6 -100 -100 -100 -100    6    6\n",
            "  -100    2 -100 -100 -100 -100 -100 -100 -100    9 -100    9 -100 -100\n",
            "    16 -100 -100 -100 -100   17   17 -100 -100 -100   17 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6   16 -100 -100 -100\n",
            "  -100 -100 -100 -100    6    6 -100    6 -100 -100 -100 -100   16 -100\n",
            "  -100 -100 -100   17 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100    6    6 -100 -100    6 -100 -100 -100    6    6 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    7 -100    6    6    6\n",
            "  -100 -100]]\n",
            "Processed pred_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-GENDER', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Processed true_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'I-JOB', 'I-JOB', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.93      0.97      0.95       308\n",
            "               DATE       0.97      0.99      0.98       993\n",
            "             GENDER       0.84      0.95      0.89       245\n",
            "                JOB       0.79      0.24      0.37       112\n",
            "           LOCATION       0.89      0.89      0.89      2295\n",
            "               NAME       0.91      0.80      0.85       169\n",
            "       ORGANIZATION       0.71      0.79      0.75       500\n",
            "         PATIENT_ID       0.95      0.99      0.97      1067\n",
            "SYMPTOM_AND_DISEASE       0.76      0.78      0.77       619\n",
            "     TRANSPORTATION       0.91      0.97      0.94        79\n",
            "\n",
            "          micro avg       0.89      0.90      0.89      6387\n",
            "          macro avg       0.87      0.84      0.84      6387\n",
            "       weighted avg       0.89      0.90      0.89      6387\n",
            "\n",
            "Shape of predictions: (2000, 128)\n",
            "Shape of labels: (2000, 128)\n",
            "First few predictions: [[ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  0 18  6 18 18 18 18 18 18 18 18 18 18 18 18\n",
            "  18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6 10  5  5  6]\n",
            " [ 6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  6  6 14 14  6 19  6  6  6\n",
            "   6  6  6  6  6  2  2  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  6  0\n",
            "  16 17 17 17 17 17 17 17 17 17 16 17 17 17 17 17 17  6 16 16 17 17 17 17\n",
            "  17 17  6  6  6  6  6  6  6  6 16 16 17 17 17 17 17 17 17 17 17 16 17 17\n",
            "  17 17 17 17 17  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  7  7  6  6  6  6  6]]\n",
            "First few labels: [[-100    6 -100 -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100    6    6 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100   18 -100 -100\n",
            "  -100 -100   18 -100 -100 -100 -100 -100   18   18 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100   18 -100 -100 -100 -100 -100 -100\n",
            "  -100    6    6    6 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100 -100 -100    6\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100    6 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6 -100 -100   10 -100\n",
            "  -100 -100]\n",
            " [-100    6    6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100    7\n",
            "  -100    6    6   14 -100    6   19    6 -100 -100 -100 -100    6    6\n",
            "  -100    2 -100 -100 -100 -100 -100 -100 -100    9 -100    9 -100 -100\n",
            "    16 -100 -100 -100 -100   17   17 -100 -100 -100   17 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6   16 -100 -100 -100\n",
            "  -100 -100 -100 -100    6    6 -100    6 -100 -100 -100 -100   16 -100\n",
            "  -100 -100 -100   17 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100    6    6 -100 -100    6 -100 -100 -100    6    6 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    7 -100    6    6    6\n",
            "  -100 -100]]\n",
            "Processed pred_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'O', 'O', 'O', 'B-ORGANIZATION', 'B-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Processed true_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'I-JOB', 'I-JOB', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.94      0.97      0.95       308\n",
            "               DATE       0.97      0.99      0.98       993\n",
            "             GENDER       0.85      0.96      0.90       245\n",
            "                JOB       0.56      0.42      0.48       112\n",
            "           LOCATION       0.88      0.92      0.90      2295\n",
            "               NAME       0.93      0.85      0.89       169\n",
            "       ORGANIZATION       0.74      0.77      0.76       500\n",
            "         PATIENT_ID       0.98      0.99      0.99      1067\n",
            "SYMPTOM_AND_DISEASE       0.75      0.80      0.78       619\n",
            "     TRANSPORTATION       0.93      1.00      0.96        79\n",
            "\n",
            "          micro avg       0.89      0.91      0.90      6387\n",
            "          macro avg       0.85      0.87      0.86      6387\n",
            "       weighted avg       0.89      0.91      0.90      6387\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=945, training_loss=0.1582743813909551, metrics={'train_runtime': 380.1462, 'train_samples_per_second': 39.672, 'train_steps_per_second': 2.486, 'total_flos': 985314418007040.0, 'train_loss': 0.1582743813909551, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}