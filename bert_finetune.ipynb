{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb3ae4371d214130b82ecd897e5c918d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e713a4ba99d436d9efb0011bb74bf8c",
              "IPY_MODEL_5b69a6e548724954855ef5cefe8cbd45",
              "IPY_MODEL_a8f02048df2b41c396ad60400fde9134"
            ],
            "layout": "IPY_MODEL_cc26941f2a4f455d9e3fff49a0d690f7"
          }
        },
        "1e713a4ba99d436d9efb0011bb74bf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593fbc1b8eba49b7857d0d3a73329eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_0d8b4aeb193348a5891137a7c6e7df53",
            "value": "model.safetensors: 100%"
          }
        },
        "5b69a6e548724954855ef5cefe8cbd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63aa202f7954802a6bdb3b87a177b01",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d8858c31d964ca085a73b1c06b2801c",
            "value": 498818054
          }
        },
        "a8f02048df2b41c396ad60400fde9134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14174dd4d494c9c9d7f83e1bc1e54f9",
            "placeholder": "​",
            "style": "IPY_MODEL_082dae9e17754718a47db21e5482eebb",
            "value": " 499M/499M [00:01&lt;00:00, 392MB/s]"
          }
        },
        "cc26941f2a4f455d9e3fff49a0d690f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593fbc1b8eba49b7857d0d3a73329eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8b4aeb193348a5891137a7c6e7df53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63aa202f7954802a6bdb3b87a177b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8858c31d964ca085a73b1c06b2801c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d14174dd4d494c9c9d7f83e1bc1e54f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082dae9e17754718a47db21e5482eebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq datasets"
      ],
      "metadata": {
        "id": "uEkQQgj2QVPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbac481-a3af-4a9b-fd3a-855a0f7551e5",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:11:51.254570Z",
          "start_time": "2025-03-22T09:11:46.731966Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/487.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h003HVeJtt7",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:12:48.558094Z",
          "start_time": "2025-03-22T09:12:48.548360Z"
        },
        "outputId": "f398bc0f-6330-4e3e-cdbe-3e8b32120e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load data\n",
        "import os\n",
        "BASE_DIR = os.getcwd()\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "train_conll= os.path.join(DATA_DIR, \"train.conll\")\n",
        "val_conll = os.path.join(DATA_DIR, \"val.conll\")\n",
        "test_conll = os.path.join(DATA_DIR, \"test.conll\")\n",
        "print(train_conll)\n",
        "print(val_conll)\n",
        "print(test_conll)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/train.conll\n",
            "/content/data/val.conll\n",
            "/content/data/test.conll\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conll(file_path):\n",
        "    sentences = []\n",
        "    sentence_labels = []\n",
        "    unique_labels = set()  # To collect unique labels\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        current_sentence_tokens = []\n",
        "        current_sentence_labels = []\n",
        "\n",
        "        for line in file:\n",
        "            line = line.strip()  # Remove leading/trailing whitespace, including '\\n'\n",
        "\n",
        "            # If it's an empty line, sentence boundary detected\n",
        "            if not line:\n",
        "                if current_sentence_tokens:  # Check if there's a sentence to append\n",
        "                    sentences.append(' '.join(current_sentence_tokens))\n",
        "                    sentence_labels.append(' '.join(current_sentence_labels))\n",
        "                current_sentence_tokens = []  # Reset for the next sentence\n",
        "                current_sentence_labels = []  # Reset for the next sentence\n",
        "            else:\n",
        "                line_parts = line.split()  # Split line into token and label\n",
        "                current_sentence_tokens.append(line_parts[0])\n",
        "\n",
        "                if len(line_parts) >= 2:\n",
        "                    current_sentence_labels.append(line_parts[1])\n",
        "                    unique_labels.add(line_parts[1])  # Add label to the set of unique labels\n",
        "                else:\n",
        "                    current_sentence_labels.append('O')  # Default to 'O' if no label provided\n",
        "\n",
        "    # Append the last sentence if the file doesn't end with an empty line\n",
        "    if current_sentence_tokens:\n",
        "        sentences.append(' '.join(current_sentence_tokens))\n",
        "        sentence_labels.append(' '.join(current_sentence_labels))\n",
        "\n",
        "    print(f\"Unique labels found: {unique_labels}\")\n",
        "    return sentences, sentence_labels\n",
        "\n",
        "# Load the datasets\n",
        "test_sentences, test_labels = read_conll(test_conll)\n",
        "dev_sentences, dev_labels = read_conll(val_conll)\n",
        "train_sentences, train_labels = read_conll(train_conll)\n",
        "\n",
        "# Now, test_sentences, test_labels, dev_sentences, dev_labels, train_sentences, and train_labels are arrays of strings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "IJYBvre1KXnM",
        "outputId": "b23d5d11-2ea9-44c0-a7cc-38bf5ce545ef",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:13:14.593555Z",
          "start_time": "2025-03-22T09:13:13.384785Z"
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data/test.conll'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff8348cd9f42>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_conll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_conll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mdev_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_conll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_conll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_conll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_conll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ff8348cd9f42>\u001b[0m in \u001b[0;36mread_conll\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0munique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To collect unique labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mcurrent_sentence_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcurrent_sentence_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/test.conll'"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GOu89ewfKbcN",
        "outputId": "9c673944-feb9-477e-f9c5-1475291672c5",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:13:19.799964Z",
          "start_time": "2025-03-22T09:13:19.781055Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Nghị định Điều chỉnh thu nhập tháng đã đóng bảo hiểm xã hội đối với người lao động tham gia bảo hiểm xã hội tự nguyện Căn_cứ Luật Tổ_chức Chính_phủ ngày 25 tháng 12 năm 2001 .'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Uf52SCP5Kgzn",
        "outputId": "fc992dc9-26d5-4368-f00b-599a91fda6ca",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:13:22.405595Z",
          "start_time": "2025-03-22T09:13:22.398600Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'O O O O O O O O O O O O O O O O O O O O O O O O O O O B-L I-L I-L I-L I-L I-L I-L I-L I-L O'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Step 1: Prepare the datasets from sentences and labels\n",
        "def prepare_dataset(sentences, labels):\n",
        "    return {'tokens': sentences, 'labels': labels}\n",
        "\n",
        "train_dataset = prepare_dataset(train_sentences, train_labels)\n",
        "dev_dataset = prepare_dataset(dev_sentences, dev_labels)\n",
        "test_dataset = prepare_dataset(test_sentences, test_labels)\n",
        "\n",
        "# Step 2: Convert strings of tokens and labels into arrays\n",
        "def process_string_to_array(dataset):\n",
        "    return {\n",
        "        'tokens': [sentence.split() for sentence in dataset['tokens']],\n",
        "        'labels': [label_seq.split() for label_seq in dataset['labels']]\n",
        "    }\n",
        "\n",
        "# Step 3: Process the dataset for token and label lists\n",
        "train_dataset = process_string_to_array(train_dataset)\n",
        "dev_dataset = process_string_to_array(dev_dataset)\n",
        "test_dataset = process_string_to_array(test_dataset)\n",
        "\n",
        "# Step 4: Convert processed datasets into Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n",
        "dev_dataset = Dataset.from_dict(dev_dataset)\n",
        "test_dataset = Dataset.from_dict(test_dataset)\n",
        "\n",
        "# Print the size of each dataset and a sample for verification\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Dev dataset size: {len(dev_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "print(\"Train dataset sample:\", train_dataset[0])\n",
        "print(\"Dev dataset sample:\", dev_dataset[0])\n",
        "print(\"Test dataset sample:\", test_dataset[0])\n",
        "\n",
        "# Step 5: Define an Example class\n",
        "class Example:\n",
        "    def __init__(self, words, slot_labels, guid=None):\n",
        "        self.words = words\n",
        "        self.slot_labels = slot_labels\n",
        "        self.guid = guid\n",
        "\n",
        "# Step 6: Convert the dataset to Example objects\n",
        "def convert_to_examples(dataset):\n",
        "    return [\n",
        "        Example(words=tokens, slot_labels=labels, guid=i)\n",
        "        for i, (tokens, labels) in enumerate(zip(dataset['tokens'], dataset['labels']))\n",
        "    ]\n",
        "\n",
        "# Convert datasets into Example objects\n",
        "train_examples = convert_to_examples(train_dataset)\n",
        "dev_examples = convert_to_examples(dev_dataset)\n",
        "test_examples = convert_to_examples(test_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpwbDRI4bXY0",
        "outputId": "9aa96aac-793b-43f0-fd49-ec518d7becdb",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:13:37.825614Z",
          "start_time": "2025-03-22T09:13:24.992723Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 34180\n",
            "Dev dataset size: 4272\n",
            "Test dataset size: 4273\n",
            "Train dataset sample: {'tokens': ['Trong', 'thời_gian', 'từ', 'khi', 'nộp', 'hồ_sơ', 'đăng_ký_chủ', 'nguồn', 'thải', 'CTNH', 'cho', 'đến', 'khi', 'được', 'cấp', 'Sổ', 'đăng_ký', ',', 'chủ', 'nguồn', 'thải', 'CTNH', 'được', 'coi', 'là', 'đã', 'thực_hiện', 'trách_nhiệm', 'đăng_ký', 'về', 'việc', 'phát_sinh', 'CTNH', 'với', 'cơ_quan', 'chuyên_môn', 'về', 'bảo_vệ', 'môi_trường', 'cấp', 'tỉnh', 'theo', 'quy_định', 'tại', 'Khoản', '1', 'Điều', '70', 'Luật', 'Bảo_vệ', 'môi_trường', '.'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-L', 'I-L', 'I-L', 'O']}\n",
            "Dev dataset sample: {'tokens': ['Sửa_đổi', ',', 'bổ_sung', 'một_số', 'điều', 'của', 'Nghị_định', 'số', '204/2004/NĐ-CP', 'ngày', '14', 'tháng', '12', 'năm', '2004', 'về', 'chế_độ', 'tiền_lương', 'đối_với', 'cán_bộ', ',', 'công_chức', ',', 'viên_chức', 'và', 'lực_lượng', 'vũ_trang', '(', 'sau', 'đây', 'viết', 'tắt', 'là', 'Nghị_định', 'số', '204/2004/NĐ-CP', ')', 'như', 'sau', ':', '1', '.'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'B-NĐ', 'I-NĐ', 'I-NĐ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
            "Test dataset sample: {'tokens': ['Các', 'dự_án', 'hóa_chất', 'thuộc', 'nhóm', 'C', 'phải', 'xây_dựng', 'Kế_hoạch', 'theo', 'quy_định', 'tại', 'Thông_tư', 'số', '28/2010/TT-BCT', 'ngày', '28', 'tháng', '6', 'năm', '2010', 'của', 'Bộ', 'Công_Thương', 'quy_định', 'cụ_thể', 'một_số', 'điều', 'của', 'Luật_Hóa_chất', 'và', 'Nghị_định', 'số', '108/2008/NĐ-CP', 'ngày', '07', 'tháng', '10', 'năm', '2008', 'của', 'Chính_phủ', 'quy_định', 'chi_tiết', 'và', 'hướng_dẫn', 'thi_hành', 'một_số', 'điều', 'của', 'Luật_Hóa_chất', 'đã', 'được', 'Sở', 'Công_Thương', 'phê_duyệt', 'trước', 'ngày', 'Thông_tư', 'này', 'có', 'hiệu_lực', 'thi_hành', 'thì', 'không', 'phải', 'làm', 'hồ_sơ', 'đề_nghị', 'Bộ', 'Công_Thương', 'thẩm_định', 'và', 'phê_duyệt', 'lại', 'Kế_hoạch', '.'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TT', 'I-TT', 'I-TT', 'I-TT', 'I-TT', 'I-TT', 'I-TT', 'I-TT', 'I-TT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-L', 'O', 'B-NĐ', 'I-NĐ', 'I-NĐ', 'I-NĐ', 'I-NĐ', 'I-NĐ', 'I-NĐ', 'I-NĐ', 'I-NĐ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import os"
      ],
      "metadata": {
        "id": "KY8Z5RMYS0pU",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:13:43.619582Z",
          "start_time": "2025-03-22T09:13:43.603492Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(file_path):\n",
        "    labels = set()\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line:  # Bỏ qua dòng trống\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 2:  # Nếu có label\n",
        "                    labels.add(parts[1])\n",
        "    return labels\n",
        "\n",
        "# Gộp labels từ tất cả các file\n",
        "all_labels = set()\n",
        "for file_path in [train_conll, val_conll, test_conll]:\n",
        "    file_labels = extract_labels(file_path)\n",
        "    all_labels.update(file_labels)\n",
        "\n",
        "sorted_labels = sorted(list(all_labels))\n",
        "label_map = {label: i for i, label in enumerate(sorted_labels)}\n",
        "\n",
        "print(f\"\\n✨ Total labels: {len(label_map)}\")\n",
        "label_list= list(label_map.keys())\n",
        "print(\"Label Map:\", label_list)\n"
      ],
      "metadata": {
        "id": "gPwTywxOTC2_",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:16:01.668744Z",
          "start_time": "2025-03-22T09:16:00.973162Z"
        },
        "outputId": "038027e4-bedc-4c81-c4cc-f8aba5e7c301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✨ Total labels: 19\n",
            "Label Map: ['B-BL', 'B-HP', 'B-L', 'B-NQ', 'B-NĐ', 'B-PL', 'B-QĐ', 'B-TT', 'B-TTLT', 'I-BL', 'I-HP', 'I-L', 'I-NQ', 'I-NĐ', 'I-PL', 'I-QĐ', 'I-TT', 'I-TTLT', 'O']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "93kM19XPSvix",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:16:17.578330Z",
          "start_time": "2025-03-22T09:16:17.564214Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    max_seq_len,\n",
        "    tokenizer,\n",
        "    pad_label_id=-100,\n",
        "    cls_token_segment_id=0,\n",
        "    pad_token_segment_id=0,\n",
        "    sequence_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    # Get special tokens from the tokenizer\n",
        "    cls_token = tokenizer.cls_token\n",
        "    sep_token = tokenizer.sep_token\n",
        "    unk_token = tokenizer.unk_token\n",
        "    pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    # List to hold the converted features\n",
        "    features = []\n",
        "\n",
        "    for example_index, example in enumerate(examples):\n",
        "        # Log progress every 5000 examples\n",
        "        if example_index % 400 == 0:\n",
        "            logger.info(f\"Processing example {example_index} of {len(examples)}\")\n",
        "\n",
        "        # Tokenize each word and align its corresponding label\n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "\n",
        "        for word, label in zip(example.words, example.slot_labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "\n",
        "            # If the word cannot be tokenized, use [UNK] token\n",
        "            if not word_tokens:\n",
        "                word_tokens = [unk_token]\n",
        "\n",
        "            tokens.extend(word_tokens)\n",
        "\n",
        "            # Map string label to integer ID, apply pad_label_id for subword tokens\n",
        "            label_id = label_map[label]\n",
        "            label_ids.extend([label_id] + [pad_label_id] * (len(word_tokens) - 1))\n",
        "\n",
        "        # Handle sequence truncation for [CLS] and [SEP] tokens\n",
        "        special_tokens_count = 2\n",
        "        if len(tokens) > max_seq_len - special_tokens_count:\n",
        "            tokens = tokens[:max_seq_len - special_tokens_count]\n",
        "            label_ids = label_ids[:max_seq_len - special_tokens_count]\n",
        "\n",
        "        # Add [SEP] token at the end of the sentence\n",
        "        tokens.append(sep_token)\n",
        "        label_ids.append(pad_label_id)\n",
        "        token_type_ids = [sequence_segment_id] * len(tokens)\n",
        "\n",
        "        # Add [CLS] token at the start of the sentence\n",
        "        tokens = [cls_token] + tokens\n",
        "        label_ids = [pad_label_id] + label_ids\n",
        "        token_type_ids = [cls_token_segment_id] + token_type_ids\n",
        "\n",
        "        # Convert tokens to input IDs\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Create attention masks (1 for real tokens, 0 for padding tokens)\n",
        "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "\n",
        "        # Pad sequences to the maximum sequence length\n",
        "        padding_length = max_seq_len - len(input_ids)\n",
        "        input_ids += [pad_token_id] * padding_length\n",
        "        attention_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
        "        token_type_ids += [pad_token_segment_id] * padding_length\n",
        "        label_ids += [pad_label_id] * padding_length\n",
        "\n",
        "        # Create InputFeatures object and append it to the list of features\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids,\n",
        "                slot_labels_ids=label_ids,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return features\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "j1gDFp4WTtg2",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:16:27.100680Z",
          "start_time": "2025-03-22T09:16:27.093529Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, attention_mask, token_type_ids, slot_labels_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.slot_labels_ids = slot_labels_ids\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\""
      ],
      "metadata": {
        "id": "_1BFV0caTUT6",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:16:32.831848Z",
          "start_time": "2025-03-22T09:16:32.822156Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "tokenizer.cls_token, tokenizer.sep_token, tokenizer.unk_token, tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3jxMCeOLr8z",
        "outputId": "dd3aa9fe-6157-4190-a672-9d118f97cc0b",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:17:39.226599Z",
          "start_time": "2025-03-22T09:17:38.168502Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('<s>', '</s>', '<unk>', 1)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', add_prefix_space=True)\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_seq_len = 128  # You can adjust this based on your model/input\n",
        "\n",
        "# Convert examples to features\n",
        "train_features = convert_examples_to_features(train_examples, max_seq_len, tokenizer)\n",
        "dev_features = convert_examples_to_features(dev_examples, max_seq_len, tokenizer)\n",
        "test_features = convert_examples_to_features(test_examples, max_seq_len, tokenizer)\n"
      ],
      "metadata": {
        "id": "8L7QmU9OSkQ_",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:19:39.536Z",
          "start_time": "2025-03-22T09:18:20.784021Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Define a Dataset class to wrap the tokenized features for training\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        return {\n",
        "            'input_ids': torch.tensor(feature.input_ids, dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(feature.attention_mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(feature.token_type_ids, dtype=torch.long),\n",
        "            'labels': torch.tensor(feature.slot_labels_ids, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Convert tokenized features into PyTorch datasets\n",
        "train_dataset = NERDataset(train_features)\n",
        "dev_dataset = NERDataset(dev_features)\n",
        "test_dataset = NERDataset(test_features)\n"
      ],
      "metadata": {
        "id": "wIpgQ1koT5um",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:20:00.311452Z",
          "start_time": "2025-03-22T09:20:00.305009Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbw028u8Na6Z",
        "outputId": "13d27053-fbb6-4426-c14a-0daa70b3ed7e",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:20:05.275386Z",
          "start_time": "2025-03-22T09:20:04.156031Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    0,  2393,  1657,  3553,  1376,  2023,    46,   118,  1215, 42859,\n",
              "           326,  1376,  2023,  4958,   449,  3592,   295,  1376,  2023,    27,\n",
              "           642,  1368,  1376,  2023,  9085,  1215,    29,  8188,  5543,  4236,\n",
              "          3602,   649,   862,  2590,  1215,   330,  3849, 10809,  1215,   611,\n",
              "          1376,  2023,  6248,   295,  5521,  1376,  2023,  9085,   282,  3553,\n",
              "          1376,  3070,  2469,   118, 12464, 28812, 14310,  4236,  3602,  1376,\n",
              "          3070,  9470,   282,   449,  3592,  4236,  3602,  8188,  7487,  1376,\n",
              "          2023,  2469,   438,   740,  1376,  3070,  8210,   642,   208,  1376,\n",
              "          2023, 15722,  4236,  3602,   649,   862,  2590,  1215,   330,  3849,\n",
              "         10809,  2156,  1855,  1376,  2023,  6248,   295,  5521,  1376,  2023,\n",
              "          9085,   282,  3553,  1376,  3070,  2469,   118, 12464, 28812,  4236,\n",
              "          3602,  8188,  7487,  1376,  2023,  2469,   438,  1029,   118,   784,\n",
              "          5269,  4236,  3602, 17682,  3553,  1376,  2023,     2]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor([-100,   18, -100,   18, -100, -100, -100, -100, -100, -100,   18, -100,\n",
              "         -100, -100,   18, -100,   18, -100, -100, -100, -100,   18, -100, -100,\n",
              "         -100, -100, -100, -100, -100,   18, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100,   18, -100, -100, -100, -100,\n",
              "         -100,   18, -100, -100, -100, -100,   18, -100,   18,   18, -100, -100,\n",
              "         -100, -100, -100,   18, -100,   18, -100, -100, -100, -100, -100, -100,\n",
              "         -100,   18, -100, -100, -100, -100,   18, -100, -100, -100,   18, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100,   18,   18, -100, -100, -100,\n",
              "           18, -100, -100, -100, -100, -100,   18, -100, -100, -100, -100,   18,\n",
              "         -100,   18, -100, -100, -100, -100, -100, -100, -100,   18, -100,   18,\n",
              "         -100,   18, -100, -100,   18, -100, -100, -100])}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForTokenClassification\n",
        "\n",
        "# Define the number of unique labels (ensure this matches your dataset's label set)\n",
        "num_labels = len(label_list)  # e.g., the number of unique labels such as O, B-ORG, etc.\n",
        "\n",
        "# Load the RoBERTa model for token classification\n",
        "model = RobertaForTokenClassification.from_pretrained('roberta-base', num_labels=num_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "eb3ae4371d214130b82ecd897e5c918d",
            "1e713a4ba99d436d9efb0011bb74bf8c",
            "5b69a6e548724954855ef5cefe8cbd45",
            "a8f02048df2b41c396ad60400fde9134",
            "cc26941f2a4f455d9e3fff49a0d690f7",
            "593fbc1b8eba49b7857d0d3a73329eb5",
            "0d8b4aeb193348a5891137a7c6e7df53",
            "e63aa202f7954802a6bdb3b87a177b01",
            "6d8858c31d964ca085a73b1c06b2801c",
            "d14174dd4d494c9c9d7f83e1bc1e54f9",
            "082dae9e17754718a47db21e5482eebb"
          ]
        },
        "id": "4giDkLYOUB57",
        "outputId": "69636a80-5b44-48ee-8021-06e688de857e",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:20:17.071970Z",
          "start_time": "2025-03-22T09:20:16.174717Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-22T09:23:41.823368Z",
          "start_time": "2025-03-22T09:23:41.816246Z"
        },
        "id": "D6Nc_VGNlu3W",
        "outputId": "8843b549-d03a-41b0-d94d-208ffee0edf8"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir = './results'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"created folder: {output_dir}\")\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created folder: ./results\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,           # output directory to save model checkpoints and results\n",
        "    evaluation_strategy=\"epoch\",      # evaluation is done at the end of every epoch\n",
        "    per_device_train_batch_size=16,   # batch size per device during training\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    num_train_epochs=3,               # number of epochs to train the model\n",
        "    weight_decay=0.01,                # strength of weight decay\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,                 # log every 10 steps\n",
        "    save_steps=500,                   # save model checkpoint every 500 steps\n",
        "    save_total_limit=2,               # limit the number of total checkpoints to save\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD9Coch-UECW",
        "outputId": "74724e71-536e-4131-8a8a-8fba5ba76a58",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:24:26.983280Z",
          "start_time": "2025-03-22T09:24:26.903519Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CmjNJmGW8Qe",
        "outputId": "2c8d0610-8765-409d-ca4d-d1250cbc617d",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:24:32.720796Z",
          "start_time": "2025-03-22T09:24:29.947994Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in c:\\users\\admin\\miniconda3\\lib\\site-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C3PSdHdY0zE",
        "outputId": "472e7d93-8014-44c1-f831-9eff2af8e42a",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:24:36.379635Z",
          "start_time": "2025-03-22T09:24:36.372658Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['B-BL',\n",
              " 'B-HP',\n",
              " 'B-L',\n",
              " 'B-NQ',\n",
              " 'B-NĐ',\n",
              " 'B-PL',\n",
              " 'B-QĐ',\n",
              " 'B-TT',\n",
              " 'B-TTLT',\n",
              " 'I-BL',\n",
              " 'I-HP',\n",
              " 'I-L',\n",
              " 'I-NQ',\n",
              " 'I-NĐ',\n",
              " 'I-PL',\n",
              " 'I-QĐ',\n",
              " 'I-TT',\n",
              " 'I-TTLT',\n",
              " 'O']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EvalPrediction\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions = p.predictions.argmax(axis=2)  # Get predicted label indices\n",
        "    labels = p.label_ids  # True label IDs\n",
        "\n",
        "    # Debugging: Print shapes of predictions and labels\n",
        "    print(f\"Shape of predictions: {predictions.shape}\")\n",
        "    print(f\"Shape of labels: {labels.shape}\")\n",
        "\n",
        "    # Debugging: Log first few predictions and labels for inspection\n",
        "    print(f\"First few predictions: {predictions[:2]}\")\n",
        "    print(f\"First few labels: {labels[:2]}\")\n",
        "\n",
        "    pred_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Iterate through predictions and labels\n",
        "    for i, (pred_seq, true_seq) in enumerate(zip(predictions, labels)):\n",
        "        pred_label_seq = []\n",
        "        true_label_seq = []\n",
        "\n",
        "        # Iterate through each token in the sequence\n",
        "        for pred_idx, true_idx in zip(pred_seq, true_seq):\n",
        "            if true_idx == -100:\n",
        "                # Debugging: Log any padding tokens encountered\n",
        "                # print(f\"Padding token encountered at position {i}\")\n",
        "                continue\n",
        "\n",
        "            # Check if the indices are within the valid range\n",
        "            if pred_idx < len(label_list) and true_idx < len(label_list):\n",
        "                pred_label_seq.append(label_list[pred_idx])\n",
        "                true_label_seq.append(label_list[true_idx])\n",
        "            else:\n",
        "                # Debugging: Log when out-of-bound indices are encountered\n",
        "                print(f\"Index out of range: pred_idx={pred_idx}, true_idx={true_idx} at position {i}\")\n",
        "\n",
        "        pred_labels.append(pred_label_seq)\n",
        "        true_labels.append(true_label_seq)\n",
        "\n",
        "    # Debugging: Log final processed predictions and labels\n",
        "    print(f\"Processed pred_labels: {pred_labels[:2]}\")\n",
        "    print(f\"Processed true_labels: {true_labels[:2]}\")\n",
        "\n",
        "    # Compute token-level F1, Precision, and Recall\n",
        "    precision = precision_score(true_labels, pred_labels)\n",
        "    # Trong 10 lần dự đoán nhãn PER: thì chúng ta đoán đúng 6 lần -> 6/10 = 60%\n",
        "\n",
        "    recall = recall_score(true_labels, pred_labels)\n",
        "    # Trong 8 nhãn PER thật: thì chúng ta đoán đúng 6 lần -> 6/8 = 75%\n",
        "\n",
        "    f1 = f1_score(true_labels, pred_labels)\n",
        "\n",
        "    # Debugging: Print classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true_labels, pred_labels))\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ],
      "metadata": {
        "id": "L3gD8zJQW4j_",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:24:52.931022Z",
          "start_time": "2025-03-22T09:24:52.921959Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "from transformers import EvalPrediction\n"
      ],
      "metadata": {
        "id": "ot0X4_cLb1vT",
        "ExecuteTime": {
          "end_time": "2025-03-22T09:24:59.684592Z",
          "start_time": "2025-03-22T09:24:59.672166Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer with the modified compute_metrics function\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics  # Updated function\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "jxgd98KnUJzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7317bd74-6896-4f61-a020-ececcbe2e60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 06:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>0.252638</td>\n",
              "      <td>0.789760</td>\n",
              "      <td>0.840457</td>\n",
              "      <td>0.814320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.060800</td>\n",
              "      <td>0.131611</td>\n",
              "      <td>0.885309</td>\n",
              "      <td>0.899170</td>\n",
              "      <td>0.892186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.056100</td>\n",
              "      <td>0.127506</td>\n",
              "      <td>0.885836</td>\n",
              "      <td>0.913574</td>\n",
              "      <td>0.899491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of predictions: (2000, 128)\n",
            "Shape of labels: (2000, 128)\n",
            "First few predictions: [[ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 16  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6 16 17  6  6 17 17 17 17 17 17 17  6  6  6  6\n",
            "   6  6  6 16 16 17 17 17 17  6 16 17 17 17 17 17 17 17 17 17  6 17 17  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6 10  5  5  6]\n",
            " [ 6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  6  6 14  6  6 19  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 16\n",
            "  16 17 17 17 17 17 17 17 17  6 16 17 17  6 17 17 17  6 16 16  6 17 17 17\n",
            "  17 17  6  6  6  6  6  6  6  6 16 16 17 17 17 17 17 17 17 17  6 16 17 17\n",
            "  17  6 17  6 17  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  7  7  6  6  6  6  6]]\n",
            "First few labels: [[-100    6 -100 -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100    6    6 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100   18 -100 -100\n",
            "  -100 -100   18 -100 -100 -100 -100 -100   18   18 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100   18 -100 -100 -100 -100 -100 -100\n",
            "  -100    6    6    6 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100 -100 -100    6\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100    6 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6 -100 -100   10 -100\n",
            "  -100 -100]\n",
            " [-100    6    6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100    7\n",
            "  -100    6    6   14 -100    6   19    6 -100 -100 -100 -100    6    6\n",
            "  -100    2 -100 -100 -100 -100 -100 -100 -100    9 -100    9 -100 -100\n",
            "    16 -100 -100 -100 -100   17   17 -100 -100 -100   17 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6   16 -100 -100 -100\n",
            "  -100 -100 -100 -100    6    6 -100    6 -100 -100 -100 -100   16 -100\n",
            "  -100 -100 -100   17 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100    6    6 -100 -100    6 -100 -100 -100    6    6 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    7 -100    6    6    6\n",
            "  -100 -100]]\n",
            "Processed pred_labels: [['O', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOCATION', 'B-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Processed true_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'I-JOB', 'I-JOB', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.88      0.97      0.92       308\n",
            "               DATE       0.94      0.99      0.96       993\n",
            "             GENDER       0.85      0.94      0.90       245\n",
            "                JOB       0.00      0.00      0.00       112\n",
            "           LOCATION       0.70      0.88      0.78      2295\n",
            "               NAME       0.96      0.73      0.83       169\n",
            "       ORGANIZATION       0.54      0.33      0.41       500\n",
            "         PATIENT_ID       0.93      0.98      0.96      1067\n",
            "SYMPTOM_AND_DISEASE       0.71      0.70      0.70       619\n",
            "     TRANSPORTATION       0.86      0.85      0.85        79\n",
            "\n",
            "          micro avg       0.79      0.84      0.81      6387\n",
            "          macro avg       0.74      0.74      0.73      6387\n",
            "       weighted avg       0.78      0.84      0.80      6387\n",
            "\n",
            "Shape of predictions: (2000, 128)\n",
            "Shape of labels: (2000, 128)\n",
            "First few predictions: [[ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  0 18  6 18 18 18 18 18 18 18 18 18 18 18 18\n",
            "  18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6 10  5  5  6]\n",
            " [ 6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  6  6 14  6  6 19  6  6  6\n",
            "   6  6  6  6  6 14  6  6  6  6  6  6  6  6  6  6  6 17  6  6  6  6  6 16\n",
            "  17 17 17 17 17 17 17 17 17 17 16 17 17 17 17 17 17  6 16 17 17 17 17 17\n",
            "  17 17  6  6  6  6  6  6  6  6 16 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
            "  17 17 17  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   7  7  7  6  6  6  6  6]]\n",
            "First few labels: [[-100    6 -100 -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100    6    6 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100   18 -100 -100\n",
            "  -100 -100   18 -100 -100 -100 -100 -100   18   18 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100   18 -100 -100 -100 -100 -100 -100\n",
            "  -100    6    6    6 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100 -100 -100    6\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100    6 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6 -100 -100   10 -100\n",
            "  -100 -100]\n",
            " [-100    6    6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100    7\n",
            "  -100    6    6   14 -100    6   19    6 -100 -100 -100 -100    6    6\n",
            "  -100    2 -100 -100 -100 -100 -100 -100 -100    9 -100    9 -100 -100\n",
            "    16 -100 -100 -100 -100   17   17 -100 -100 -100   17 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6   16 -100 -100 -100\n",
            "  -100 -100 -100 -100    6    6 -100    6 -100 -100 -100 -100   16 -100\n",
            "  -100 -100 -100   17 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100    6    6 -100 -100    6 -100 -100 -100    6    6 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    7 -100    6    6    6\n",
            "  -100 -100]]\n",
            "Processed pred_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-GENDER', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Processed true_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'I-JOB', 'I-JOB', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.93      0.97      0.95       308\n",
            "               DATE       0.97      0.99      0.98       993\n",
            "             GENDER       0.84      0.95      0.89       245\n",
            "                JOB       0.79      0.24      0.37       112\n",
            "           LOCATION       0.89      0.89      0.89      2295\n",
            "               NAME       0.91      0.80      0.85       169\n",
            "       ORGANIZATION       0.71      0.79      0.75       500\n",
            "         PATIENT_ID       0.95      0.99      0.97      1067\n",
            "SYMPTOM_AND_DISEASE       0.76      0.78      0.77       619\n",
            "     TRANSPORTATION       0.91      0.97      0.94        79\n",
            "\n",
            "          micro avg       0.89      0.90      0.89      6387\n",
            "          macro avg       0.87      0.84      0.84      6387\n",
            "       weighted avg       0.89      0.90      0.89      6387\n",
            "\n",
            "Shape of predictions: (2000, 128)\n",
            "Shape of labels: (2000, 128)\n",
            "First few predictions: [[ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  0 18  6 18 18 18 18 18 18 18 18 18 18 18 18\n",
            "  18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  6  6  6 10  5  5  6]\n",
            " [ 6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  6  6 14 14  6 19  6  6  6\n",
            "   6  6  6  6  6  2  2  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  6  0\n",
            "  16 17 17 17 17 17 17 17 17 17 16 17 17 17 17 17 17  6 16 16 17 17 17 17\n",
            "  17 17  6  6  6  6  6  6  6  6 16 16 17 17 17 17 17 17 17 17 17 16 17 17\n",
            "  17 17 17 17 17  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "   6  7  7  6  6  6  6  6]]\n",
            "First few labels: [[-100    6 -100 -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100    6    6 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100   18 -100 -100\n",
            "  -100 -100   18 -100 -100 -100 -100 -100   18   18 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100   18 -100 -100 -100 -100 -100 -100\n",
            "  -100    6    6    6 -100 -100 -100 -100    6 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100 -100 -100    6\n",
            "  -100 -100 -100 -100 -100    6 -100 -100 -100 -100 -100    6 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6 -100 -100   10 -100\n",
            "  -100 -100]\n",
            " [-100    6    6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100    7\n",
            "  -100    6    6   14 -100    6   19    6 -100 -100 -100 -100    6    6\n",
            "  -100    2 -100 -100 -100 -100 -100 -100 -100    9 -100    9 -100 -100\n",
            "    16 -100 -100 -100 -100   17   17 -100 -100 -100   17 -100 -100 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    6   16 -100 -100 -100\n",
            "  -100 -100 -100 -100    6    6 -100    6 -100 -100 -100 -100   16 -100\n",
            "  -100 -100 -100   17 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "  -100 -100 -100    6    6 -100 -100    6 -100 -100 -100    6    6 -100\n",
            "  -100 -100 -100 -100 -100 -100 -100 -100 -100    7 -100    6    6    6\n",
            "  -100 -100]]\n",
            "Processed pred_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'O', 'O', 'O', 'B-ORGANIZATION', 'B-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Processed true_labels: [['O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE'], ['O', 'O', 'B-PATIENT_ID', 'O', 'O', 'B-GENDER', 'O', 'B-AGE', 'O', 'O', 'O', 'B-JOB', 'I-JOB', 'I-JOB', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'B-LOCATION', 'O', 'O', 'O', 'B-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O']]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.94      0.97      0.95       308\n",
            "               DATE       0.97      0.99      0.98       993\n",
            "             GENDER       0.85      0.96      0.90       245\n",
            "                JOB       0.56      0.42      0.48       112\n",
            "           LOCATION       0.88      0.92      0.90      2295\n",
            "               NAME       0.93      0.85      0.89       169\n",
            "       ORGANIZATION       0.74      0.77      0.76       500\n",
            "         PATIENT_ID       0.98      0.99      0.99      1067\n",
            "SYMPTOM_AND_DISEASE       0.75      0.80      0.78       619\n",
            "     TRANSPORTATION       0.93      1.00      0.96        79\n",
            "\n",
            "          micro avg       0.89      0.91      0.90      6387\n",
            "          macro avg       0.85      0.87      0.86      6387\n",
            "       weighted avg       0.89      0.91      0.90      6387\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=945, training_loss=0.1582743813909551, metrics={'train_runtime': 380.1462, 'train_samples_per_second': 39.672, 'train_steps_per_second': 2.486, 'total_flos': 985314418007040.0, 'train_loss': 0.1582743813909551, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}